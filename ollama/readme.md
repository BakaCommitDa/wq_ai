# ollama

它是一个让你能通过简单命令在本地轻松下载、运行、和管理大模型的工具。
GPU加速和类OPEANAI 接口， 适合本地部署和开发。


Meta Llama 羊驼
deepseek-r1:1.5b  参数的尺寸
pull deepseek-r1:1.5b
ollama run deepseek-r1:1.5b
Qwen 


在11434端口提供api 调用
